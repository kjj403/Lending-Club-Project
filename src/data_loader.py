import os
import numpy as np
import pandas as pd
from tqdm import tqdm
import config

def _get_irr_cache_path() -> str:
    if hasattr(config, "IRR_CACHE_PATH"):
        return config.IRR_CACHE_PATH
    base_dir = getattr(config, "BASE_DIR", os.getcwd())
    return os.path.join(base_dir, "../data/cache/actual_irr_cache.parquet")

def load_processed_data():
    if not os.path.exists(config.DATA_PATH):
        raise FileNotFoundError(f"ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {config.DATA_PATH}")
        
    df = pd.read_parquet(config.DATA_PATH)
    
    # [ìˆ˜ì •ë¨] ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¨ í›„ Pandas í™˜ê²½ì—ì„œ ì•ˆì „í•˜ê²Œ Categorical íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    cat_targets = ['home_ownership', 'purpose', 'initial_list_status', 'grade', 'sub_grade', 'verification_status']
    existing_cats = [c for c in cat_targets if c in df.columns]
    for c in existing_cats:
        df[c] = df[c].astype('category')
        
    return df

def load_treasury_rates():
    """
    ë¬´ìœ„í—˜ ì´ììœ¨ ì‚°ì¶œì„ ìœ„í•œ êµ­ì±„ ê¸ˆë¦¬ ë°ì´í„°(3ë…„ë¬¼, 5ë…„ë¬¼) ë¡œë“œ ë° ë³´ê°„
    """
    try:
        gs3 = pd.read_csv(config.GS3_PATH)
        gs5 = pd.read_csv(config.GS5_PATH)

        gs3.columns = [c.strip().lower() for c in gs3.columns]
        gs5.columns = [c.strip().lower() for c in gs5.columns]

        if "observation_date" in gs3.columns:
            gs3.rename(columns={"observation_date": "DATE"}, inplace=True)
        if "observation_date" in gs5.columns:
            gs5.rename(columns={"observation_date": "DATE"}, inplace=True)

        gs3["DATE"] = pd.to_datetime(gs3["DATE"], errors="coerce")
        gs5["DATE"] = pd.to_datetime(gs5["DATE"], errors="coerce")

        if "gs3" in gs3.columns:
            gs3.rename(columns={"gs3": "GS3"}, inplace=True)
        elif len(gs3.columns) > 1:
            col_name = [c for c in gs3.columns if c != "DATE"][0]
            gs3.rename(columns={col_name: "GS3"}, inplace=True)

        if "gs5" in gs5.columns:
            gs5.rename(columns={"gs5": "GS5"}, inplace=True)
        elif len(gs5.columns) > 1:
            col_name = [c for c in gs5.columns if c != "DATE"][0]
            gs5.rename(columns={col_name: "GS5"}, inplace=True)

        gs3["GS3"] = pd.to_numeric(gs3["GS3"], errors="coerce")
        gs5["GS5"] = pd.to_numeric(gs5["GS5"], errors="coerce")

        gs3 = gs3.dropna(subset=["DATE"]).sort_values("DATE").set_index("DATE").resample("D").interpolate().reset_index()
        gs5 = gs5.dropna(subset=["DATE"]).sort_values("DATE").set_index("DATE").resample("D").interpolate().reset_index()

        print(f"âœ… ê±°ì‹œê²½ì œ ì§€í‘œ(êµ­ì±„ ê¸ˆë¦¬) ë¡œë“œ ì™„ë£Œ: GS3({len(gs3)}ê±´), GS5({len(gs5)}ê±´)")
        return gs3, gs5

    except Exception as e:
        print(f"âš ï¸ êµ­ì±„ ê¸ˆë¦¬ ë¡œë“œ ì‹¤íŒ¨. ìƒì„¸ ë‚´ì—­: {e}")
        return None, None

def map_risk_free_rate(df):
    """
    ëŒ€ì¶œ ë§Œê¸°(Term) ë° ë°œí–‰ì¼(Issue Date)ì— ë§ì¶˜ ë¬´ìœ„í—˜ ì´ììœ¨(Risk-Free Rate) ë™ì  ë§¤í•‘
    """
    gs3, gs5 = load_treasury_rates()

    if gs3 is None or gs5 is None:
        print("âš ï¸ êµ­ì±„ ë°ì´í„° ëˆ„ë½ìœ¼ë¡œ ì¸í•˜ì—¬ ê¸°ë³¸ ë¬´ìœ„í—˜ ì´ììœ¨(2%)ì„ ì¼ê´„ ì ìš©í•©ë‹ˆë‹¤.")
        return df

    out = df.copy()
    if "risk_free_rate" not in out.columns:
        out["risk_free_rate"] = np.nan

    out["issue_d_parsed"] = pd.to_datetime(out["issue_d"], format="%b-%Y", errors="coerce")
    out["term_str"] = out["term"].astype(str).str.strip()

    mask_36 = out["term_str"].str.contains("36", na=False) & out["issue_d_parsed"].notna()
    mask_60 = out["term_str"].str.contains("60", na=False) & out["issue_d_parsed"].notna()

    if mask_36.any():
        base_36 = out.loc[mask_36, ["issue_d_parsed"]].copy()
        base_36["__idx__"] = base_36.index
        base_36 = base_36.sort_values("issue_d_parsed")
        merged_36 = pd.merge_asof(
            base_36,
            gs3.sort_values("DATE"),
            left_on="issue_d_parsed",
            right_on="DATE",
            direction="backward",
        )
        out.loc[merged_36["__idx__"].to_numpy(), "risk_free_rate"] = merged_36["GS3"].to_numpy() / 100.0

    if mask_60.any():
        base_60 = out.loc[mask_60, ["issue_d_parsed"]].copy()
        base_60["__idx__"] = base_60.index
        base_60 = base_60.sort_values("issue_d_parsed")
        merged_60 = pd.merge_asof(
            base_60,
            gs5.sort_values("DATE"),
            left_on="issue_d_parsed",
            right_on="DATE",
            direction="backward",
        )
        out.loc[merged_60["__idx__"].to_numpy(), "risk_free_rate"] = merged_60["GS5"].to_numpy() / 100.0

    out.drop(columns=["issue_d_parsed", "term_str"], inplace=True, errors="ignore")
    return out

def _solve_monthly_rate_annuity(principal: float, pmt: float, n_months: int) -> float:
    """ë“±ê°€ì—°ê¸ˆ(Annuity) ë°©ì‹ì˜ ì›”ë³„ ë‚´ë¶€ìˆ˜ìµë¥ (IRR) ì‚°ì¶œì„ ìœ„í•œ ì´ë¶„ íƒìƒ‰ ìˆ˜ì¹˜í•´ì„"""
    if principal <= 0 or pmt <= 0 or n_months <= 0:
        return np.nan

    n = int(n_months)

    def npv(r):
        if r <= -0.9999:
            return np.nan
        d = 1.0 + r
        if abs(r) < 1e-12:
            pv = pmt * n
        else:
            pv = pmt * (1.0 - d ** (-n)) / r
        return -principal + pv

    lo, hi = -0.999, 5.0
    f_lo, f_hi = npv(lo), npv(hi)

    if np.isnan(f_lo) or np.isnan(f_hi):
        return np.nan

    k = 0
    while f_lo * f_hi > 0 and k < 20:
        hi *= 1.5
        f_hi = npv(hi)
        if np.isnan(f_hi):
            return np.nan
        k += 1

    if f_lo * f_hi > 0:
        return np.nan

    for _ in range(60):
        mid = 0.5 * (lo + hi)
        f_mid = npv(mid)
        if np.isnan(f_mid):
            return np.nan
        if abs(f_mid) < 1e-8:
            return mid
        if f_lo * f_mid <= 0:
            hi, f_hi = mid, f_mid
        else:
            lo, f_lo = mid, f_mid

    return 0.5 * (lo + hi)

def _solve_monthly_irr_optimized(row_tuple):
    """
    ë‹¨ì¼ í˜„ê¸ˆíë¦„(Balloon Payment) ê¸°ë°˜ì˜ ì—°í™˜ì‚° ë‚´ë¶€ìˆ˜ìµë¥ (IRR) ìµœì í™” ì—°ì‚°
    """
    principal, installment, n_months, total_inflow = row_tuple

    if principal <= 0 or total_inflow <= 0 or n_months <= 0:
        return np.nan

    n = int(n_months)
    reg_n = max(0, n - 1)

    # ë§ˆì§€ë§‰ ê¸°ì¼ì— ì”ì—¬ í˜„ê¸ˆíë¦„ì´ ì§‘ì¤‘ëœë‹¤ëŠ” ê°€ì •(Balloon payment)
    balloon = total_inflow - (installment * reg_n)

    # í˜„ê¸ˆíë¦„ êµ¬ì¡°ìƒ Balloonì´ ìŒìˆ˜ì¸ ê²½ìš° ë“±ê°€ì—°ê¸ˆ(Annuity) ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´ ì—°ì‚°
    if balloon <= 0:
        pmt_new = total_inflow / n
        r_m = _solve_monthly_rate_annuity(principal, pmt_new, n)
        if np.isnan(r_m):
            return np.nan
        return (1.0 + r_m) ** 12 - 1.0

    def npv(r):
        if r <= -0.9999:
            return np.nan
        d = 1.0 + r

        if reg_n == 0:
            pv_reg = 0.0
        elif abs(r) < 1e-12:
            pv_reg = installment * reg_n
        else:
            pv_reg = installment * (1.0 - d ** (-reg_n)) / r

        pv_balloon = balloon / (d ** n)
        return -principal + pv_reg + pv_balloon

    lo, hi = -0.999, 5.0
    f_lo, f_hi = npv(lo), npv(hi)

    if np.isnan(f_lo) or np.isnan(f_hi):
        return np.nan

    k = 0
    while f_lo * f_hi > 0 and k < 20:
        hi *= 1.5
        f_hi = npv(hi)
        if np.isnan(f_hi):
            return np.nan
        k += 1

    if f_lo * f_hi > 0:
        return np.nan

    for _ in range(60):
        mid = 0.5 * (lo + hi)
        f_mid = npv(mid)

        if np.isnan(f_mid):
            return np.nan
        if abs(f_mid) < 1e-8:
            return (1.0 + mid) ** 12 - 1.0

        if f_lo * f_mid <= 0:
            hi, f_hi = mid, f_mid
        else:
            lo, f_lo = mid, f_mid

    return (1.0 + 0.5 * (lo + hi)) ** 12 - 1.0

def calculate_actual_irr(df):
    """ë°ì´í„°í”„ë ˆì„ ë‚´ ê°œë³„ ëŒ€ì¶œ ê±´ì— ëŒ€í•œ ë‚´ë¶€ìˆ˜ìµë¥ (IRR) ì¼ê´„ ê³„ì‚°"""
    print("â³ ëŒ€ì¶œ ìƒí™˜ ì´ë ¥ ê¸°ë°˜ ë‚´ë¶€ìˆ˜ìµë¥ (IRR) ì—°ì‚° ì¤‘...")

    out = df.copy()
    if "actual_irr" in out.columns:
        out.drop(columns=["actual_irr"], inplace=True)

    issue_dt = pd.to_datetime(out["issue_d"], format="%b-%Y", errors="coerce")
    last_dt = pd.to_datetime(out["last_pymnt_d"], format="%b-%Y", errors="coerce")
    out["n_months"] = ((last_dt - issue_dt).dt.days / 30.4375).round().clip(lower=1).fillna(0).astype(int)

    if "total_pymnt" not in out.columns:
        out["total_pymnt"] = (
            pd.to_numeric(out["total_rec_prncp"], errors="coerce").fillna(0.0)
            + pd.to_numeric(out["total_rec_int"], errors="coerce").fillna(0.0)
            + pd.to_numeric(out["recoveries"], errors="coerce").fillna(0.0)
        )

    out["funded_amnt"] = pd.to_numeric(out["funded_amnt"], errors="coerce")
    out["installment"] = pd.to_numeric(out["installment"], errors="coerce")
    out["total_pymnt"] = pd.to_numeric(out["total_pymnt"], errors="coerce")

    terminal = out["loan_status"].isin(["Fully Paid", "Charged Off", "Default"])

    out["_k_principal"] = out["funded_amnt"].round(2)
    out["_k_install"] = out["installment"].round(2)
    out["_k_total"] = out["total_pymnt"].round(2)

    key_cols = ["_k_principal", "_k_install", "n_months", "_k_total"]

    valid = (
        terminal
        & out["_k_principal"].notna() & (out["_k_principal"] > 0)
        & out["_k_install"].notna() & (out["_k_install"] >= 0)
        & out["_k_total"].notna() & (out["_k_total"] > 0)
        & (out["n_months"] > 0)
    )

    target_df = out.loc[valid, key_cols].copy()
    unique_cases = target_df.drop_duplicates()

    print(f"   - ì „ì²´ ì—°ì‚° ëŒ€ìƒ: {len(target_df):,}ê±´ / ìœ ë‹ˆí¬(ë³‘í•©) ì—°ì‚°: {len(unique_cases):,}ê±´")

    records = unique_cases.to_records(index=False)
    results = []
    for row in tqdm(records, desc="IRR Solving"):
        results.append(_solve_monthly_irr_optimized(row))

    unique_cases["actual_irr"] = np.array(results, dtype=float)

    out = out.join(unique_cases.set_index(key_cols)["actual_irr"], on=key_cols)
    out["actual_irr"] = out["actual_irr"].clip(lower=-1.0, upper=3.0)

    out.drop(columns=["_k_principal", "_k_install", "_k_total", "n_months"], inplace=True, errors="ignore")
    return out

def attach_cached_actual_irr(df, force_recompute=False):
    """ì—°ì‚° ì‹œê°„ ë‹¨ì¶•ì„ ìœ„í•œ ìºì‹±(Caching) ê¸°ë²• ê¸°ë°˜ IRR ê²°í•©"""
    out = df.copy()
    cache_path = _get_irr_cache_path()

    if "id" in out.columns:
        key_col = "id"
    else:
        hash_cols = [c for c in ["issue_d", "last_pymnt_d", "funded_amnt", "installment", "loan_status"] if c in out.columns]
        if len(hash_cols) == 0:
            raise ValueError("ê³ ìœ  ì‹ë³„(Hash) í‚¤ ìƒì„±ì„ ìœ„í•œ í•„ìˆ˜ ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        out["_irr_key"] = pd.util.hash_pandas_object(out[hash_cols].astype(str), index=False).astype("int64")
        key_col = "_irr_key"

    if "actual_irr" not in out.columns:
        out["actual_irr"] = np.nan

    if (not force_recompute) and os.path.exists(cache_path):
        try:
            cache = pd.read_parquet(cache_path)
            if key_col in cache.columns and "actual_irr" in cache.columns:
                cache = cache[[key_col, "actual_irr"]].drop_duplicates(subset=[key_col], keep="last")
                out = out.merge(cache, on=key_col, how="left", suffixes=("", "_cache"))
                out["actual_irr"] = out["actual_irr"].fillna(out["actual_irr_cache"])
                out.drop(columns=["actual_irr_cache"], inplace=True, errors="ignore")
                print(f"âœ… ê¸°ì‚°ì¶œëœ IRR ìºì‹œ(Cache) ë©”ëª¨ë¦¬ ë¡œë“œ ì„±ê³µ: {cache_path}")
        except Exception as e:
            print(f"âš ï¸ IRR ìºì‹œ ë¡œë“œ ì‹¤íŒ¨ (ì¬ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤): {e}")

    need = out["actual_irr"].isna() | ~np.isfinite(out["actual_irr"])
    if need.any():
        print(f"ğŸ”„ ë¯¸ì‚°ì¶œëœ ë°ì´í„°ì— ëŒ€í•œ ì‹ ê·œ IRR ì—°ì‚° ì‹œì‘: {need.sum():,}ê±´")
        calc = calculate_actual_irr(out.loc[need].copy())
        out.loc[need, "actual_irr"] = calc["actual_irr"].values

    cache_out = out[[key_col, "actual_irr"]].dropna().drop_duplicates(subset=[key_col], keep="last")
    os.makedirs(os.path.dirname(cache_path), exist_ok=True)
    cache_out.to_parquet(cache_path, index=False)

    if key_col == "_irr_key":
        out.drop(columns=["_irr_key"], inplace=True, errors="ignore")

    return out

def compute_sample_weights(df, default_penalty=1.5):
    """
    ë¹„ìš© ë¯¼ê° í•™ìŠµ(Cost-sensitive Learning)ì„ ìœ„í•œ ìƒ˜í”Œë³„ ê°€ì¤‘ì¹˜ ì‚°ì¶œ ì•Œê³ ë¦¬ì¦˜
    - ê³ ì•¡ ëŒ€ì¶œ ë¶€ë„ ê±´ì— ëŒ€í•œ ëª¨ë¸ì˜ ê³¼ì í•©(ê°€ì¤‘ì¹˜ í­ì£¼)ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë¡œê·¸ ìŠ¤ì¼€ì¼(Log-scale) ë°˜ì˜
    """
    weights = np.ones(len(df))
    mask_default = (df["target"] == 1)

    if "loan_amnt" in df.columns:
        amt = pd.to_numeric(df["loan_amnt"], errors="coerce").fillna(0.0).clip(lower=0.0)

        median_amount = float(np.nanmedian(amt.values))
        if median_amount <= 0:
            median_amount = 1.0

        denom = np.log1p(median_amount)
        if denom <= 0:
            denom = 1.0
        amount_factor = np.log1p(amt) / denom

        # ëª¨ë¸ ì•ˆì •ì„±ì„ ìœ„í•œ ê°€ì¤‘ì¹˜ ìƒ/í•˜í•œì„ (Clipping) ì„¤ì •
        amount_factor = amount_factor.clip(lower=0.5, upper=2.0)

        weights[mask_default] = default_penalty * amount_factor[mask_default]
    else:
        weights[mask_default] = default_penalty

    return weights

def prepare_data_with_weights():
    """ëª¨ë¸ í•™ìŠµ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸(ê°€ì¤‘ì¹˜ ì‚°ì¶œ ë° ê±°ì‹œì§€í‘œ ë§¤í•‘)"""
    print("ğŸ”„ [Step 1] íŒŒìƒ ë°ì´í„° ë¡œë“œ ë° í›ˆë ¨ ê°€ì¤‘ì¹˜ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”...")
    df = load_processed_data()

    print("ğŸ’µ ë¬´ìœ„í—˜ ì´ììœ¨(Risk-Free Rate) ë§¤í•‘ í”„ë¡œì„¸ìŠ¤ ì§„í–‰ ì¤‘...")
    try:
        df = map_risk_free_rate(df)
    except Exception as e:
        print(f"âš ï¸ ë§¤í•‘ ì¤‘ ì˜ˆì™¸ ë°œìƒ({e}). ì¼ê´„ ê¸°ë³¸ê°’ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    if "risk_free_rate" not in df.columns:
        df["risk_free_rate"] = 0.02
    else:
        df["risk_free_rate"] = df["risk_free_rate"].fillna(0.02)

    try:
        df = attach_cached_actual_irr(df, force_recompute=False)
    except Exception as e:
        print(f"âŒ IRR ì—°ì‚° íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
        return None

    if "int_rate" in df.columns:
        if df["int_rate"].mean() > 1:
            df["int_rate_spread"] = (df["int_rate"] / 100.0) - df["risk_free_rate"]
        else:
            df["int_rate_spread"] = df["int_rate"] - df["risk_free_rate"]

    print("âš–ï¸ ê¸ˆìœµ íŠ¹í™” í›ˆë ¨ ê°€ì¤‘ì¹˜(Cost-sensitive Weights) ë¶€ì—¬ ì¤‘...")
    df["sample_weight"] = compute_sample_weights(df, default_penalty=1.5)
    # ì •ê·œí™”ë¥¼ í†µí•œ í•™ìŠµ ìŠ¤ì¼€ì¼ ì•ˆì •í™”
    df["sample_weight"] = df["sample_weight"] / df["sample_weight"].mean()

    print("âœ… ë°ì´í„° ì¤€ë¹„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ (ë¶€ë„ íŒ¨ë„í‹° ë° ê¸ˆì•¡ ê°€ì¤‘ì¹˜ ì ìš© ì™„ìˆ˜)")
    return df